version: 0.2
env:
  secrets-manager:
    AWS_ACCESS_KEY_ID: "build/eks:AWS_ACCESS_KEY_ID"
    AWS_SECRET_ACCESS_KEY: "build/eks:AWS_SECRET_ACCESS_KEY"
    NEXUS_USER: "build/eks:NEXUS_USER"
    NEXUS_PASSWORD: "build/eks:NEXUS_PASSWORD"
phases:
  install:
    commands:
      - echo Preparando entorno
      - sudo yum update -y
      # Instalación de kubectl
      - curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
      - chmod +x kubectl
      - sudo mv kubectl /usr/local/bin/
      - kubectl version --client
      # Instalación de eksctl
      - curl --silent --location "https://github.com/weaveworks/eksctl/releases/download/v0.140.0/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
      - sudo mv /tmp/eksctl /usr/local/bin
      - eksctl version
      # Instalación de Helm
      - curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 > get_helm.sh
      - chmod 700 get_helm.sh
      - ./get_helm.sh
      - helm version | cut -d + -f 1
      # Instalación de Terraform
      - echo "Instalando Terraform..."
      - curl -o terraform.zip https://releases.hashicorp.com/terraform/1.5.7/terraform_1.5.7_linux_amd64.zip
      - unzip terraform.zip
      - sudo mv terraform /usr/local/bin/
      - terraform --version
      # Autenticación en Nexus
      - echo autenticando en Nexus Repository
      - pwd
      - ls -la
      - ls -la ./Scripts # Listar específicamente la carpeta de scripts para verificar
      - chmod +x ./Scripts/setup-netrc.sh
      - ./Scripts/setup-netrc.sh
      - echo "Validación del archivo .netrc completada"
      # Autenticación en AWS
      - echo "Autenticando con AWS CLI..."
      - aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID
      - aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY
      - aws configure set region $AWS_DEFAULT_REGION
      - aws sts get-caller-identity
  pre_build:
    commands:
      # Crear el cluster
      # Necesito en el terraform asegurar que las reglas de entrada y salida del cluster, incluya una que permita el trafico hacia el grupo de seguridad de quien ejecute el comando, por ejemplo en el caso de cloud9 trafico hacia y desde cluod 9 o si no no se pueden listar los nodos
      - echo "Iniciando despliegue de infraestructura con Terraform"
      - cd $CODEBUILD_SRC_DIR/Terraform && terraform init
      - cd $CODEBUILD_SRC_DIR/Terraform && terraform plan -var="aws_region=$AWS_DEFAULT_REGION" -var="cluster_name=$EKS_NAME" -var="cluster_service_role_arn=$EKS_SERVICE_ROLE_ARN" -var="node_role_arn=$EKS_NODE_ROLE_ARN"
      - cd $CODEBUILD_SRC_DIR/Terraform && terraform apply -auto-approve -var="aws_region=$AWS_DEFAULT_REGION" -var="cluster_name=$EKS_NAME" -var="cluster_service_role_arn=$EKS_SERVICE_ROLE_ARN" -var="node_role_arn=$EKS_NODE_ROLE_ARN"
      # Capturar outputs de Terraform
      - codebuild-breakpoint
      - cd $CODEBUILD_SRC_DIR/Terraform && terraform output
      - EKS_CLUSTER_ENDPOINT=$(cd $CODEBUILD_SRC_DIR/Terraform && terraform output -raw eks_cluster_endpoint)
      - export EKS_CLUSTER_ENDPOINT
      - VPC_ID=$(cd $CODEBUILD_SRC_DIR/Terraform && terraform output -raw vpc_id)
      - export VPC_ID
      - EFS_DNS_NAME=$(cd $CODEBUILD_SRC_DIR/Terraform && terraform output -raw efs_dns_name)
      - export EFS_DNS_NAME
  build:
    commands:
      - aws eks update-kubeconfig --name ${EKS_NAME} --region ${AWS_DEFAULT_REGION}
      - kubectl get nodes  
      - if ! kubectl get namespace ${NAMESPACE}; then kubectl create namespace ${NAMESPACE}; fi
      # Instalación de Alfresco Content Services 
      - kubectl create secret docker-registry quay-registry-secret --docker-server=quay.io --docker-username=$QUAY_USERNAME --docker-password=$QUAY_PASSWORD -n ${NAMESPACE}
      - helm install acs $CODEBUILD_SRC_DIR/alfresco-content-services --set externalPort="443" --set externalProtocol="https" --set externalHost="acs.tfmfc.com" --set persistence.enabled=true --set persistence.storageClass.enabled=true --set persistence.storageClass.name="nfs-client" --set alfresco-repository.persistence.existingClaim="alf-content-pvc" --set alfresco-repository.persistence.enabled=true --set global.alfrescoRegistryPullSecrets=quay-registry-secret --set alfresco-sync-service.enabled=false --set postgresql-sync.enabled=false --set alfresco-transform-service.transformrouter.replicaCount="1" --set alfresco-transform-service.pdfrenderer.replicaCount="1" --set alfresco-transform-service.imagemagick.replicaCount="1" --set alfresco-transform-service.libreoffice.replicaCount="1" --set alfresco-transform-service.tika.replicaCount="1" --set alfresco-transform-service.transformmisc.replicaCount="1" --set alfresco-transform-service.transformrouter.resources.limits.memory="2Gi" --set alfresco-transform-service.pdfrenderer.resources.limits.memory="2Gi" --set alfresco-transform-service.imagemagick.resources.limits.memory="2Gi" --set alfresco-transform-service.libreoffice.resources.limits.memory="2Gi" --set alfresco-transform-service.tika.resources.limits.memory="2Gi" --set alfresco-transform-service.transformmisc.resources.limits.memory="2Gi" --set alfresco-transform-service.transformrouter.resources.limits.cpu="250m" --set alfresco-transform-service.pdfrenderer.resources.limits.cpu="250m" --set alfresco-transform-service.imagemagick.resources.limits.cpu="250m" --set alfresco-transform-service.libreoffice.resources.limits.cpu="250m" --set alfresco-transform-service.tika.resources.limits.cpu="250m" --set alfresco-transform-service.transformmisc.resources.limits.cpu="250m" --set alfresco-transform-service.filestore.resources.limits.cpu="250m" --set postgresql.primary.resources.requests.cpu="250m" --set postgresql.primary.resources.limits.cpu="500m" --set postgresql.primary.resources.limits.memory="6Gi" --set alfresco-share.resources.limits.cpu="250m" --set alfresco-search-enterprise.resources.requests.cpu="250m" --set alfresco-search-enterprise.resources.limits.cpu="250m" --set alfresco-repository.resources.requests.cpu="500m" --set alfresco-repository.resources.limits.cpu="500m" --set alfresco-repository.readinessProbe.periodSeconds="200" --set alfresco-repository.livenessProbe.periodSeconds="200" --set alfresco-repository.startupProbe.periodSeconds="200" --set alfresco-transform-service.pdfrenderer.livenessProbe.periodSeconds="200" --set alfresco-transform-service.pdfrenderer.readinessProbe.periodSeconds="200" --set alfresco-transform-service.imagemagick.livenessProbe.periodSeconds="200" --set alfresco-transform-service.imagemagick.readinessProbe.periodSeconds="200" --set alfresco-transform-service.tika.livenessProbe.periodSeconds="200" --set alfresco-transform-service.tika.readinessProbe.periodSeconds="200" --set alfresco-transform-service.libreoffice.livenessProbe.periodSeconds="200" --set alfresco-transform-service.libreoffice.readinessProbe.periodSeconds="200" --set alfresco-transform-service.transformmisc.livenessProbe.periodSeconds="200" --set alfresco-transform-service.transformmisc.readinessProbe.periodSeconds="200" --set alfresco-search-enterprise.reindexing.enabled=false --atomic --namespace=$NAMESPACE
      - kubectl get pods -n ${NAMESPACE}
      - echo "Despliegue finalizado"
      - echo "DOMAIN_NAME=$DOMAIN_NAME"